{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 0\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang: # 딕셔너리를 만들기 위한 클래스\n",
    "    def __init__(self): # 단어의 인덱스를 저장하기 위한 컨테이너를 초기화\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"} # SOS(Start of Sequence): 문장의 시작, EOS(End of Sequence): 문장의 끝\n",
    "        self.n_words = 2 # SOS와 EOS에 대한 카운트\n",
    "\n",
    "    def addSentence(self, sentence): # 문장을 단어 단위로 분리한 후 컨테이너(word)에 추가\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word): # 컨테이너에 단어가 없다면 추가되고, 있다면 카운트를 업데이트\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else: \n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(df, lang):\n",
    "    sentence = df[lang].str.lower() # 소문자로 변환\n",
    "    sentence = sentence.str.replace('[A-Za-z\\s]+', ' ') # a-z, A-Z, ..., ?, ! 등을 제외하고 모두 공백으로 변환\n",
    "    sentence = sentence.str.normalize('NFD') # 유니코드 정규화 방식\n",
    "    sentence = sentence.str.encode('ascii', errors = 'ignore').str.decode('utf-8') # Unicode를 ASCII로 변환\n",
    "    return sentence\n",
    "\n",
    "def read_sentence(df, lang1, lang2):\n",
    "    sentence1 = normalizeString(df, lang1) # 데이터셋의 첫 번째 열(영어)\n",
    "    sentence2 = normalizeString(df, lang2) # 데이터셋의 두 번째 열(프랑스어)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "def read_file(loc, lang1, lang2):\n",
    "    df = pd.read_csv(loc, delimiter = '\\t', header = None, names = [lang1, lang2])\n",
    "    return df\n",
    "\n",
    "def process_data(lang1, lang2):\n",
    "    df = read_file('D:/kim/kim/DP/data/%s-%s.txt'%(lang1, lang2), lang1, lang2) # 데이터셋 불러오기\n",
    "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
    "\n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    pairs = []\n",
    "    for i in range(len(df)):\n",
    "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
    "            full = [sentence1[i], sentence2[i]] # 첫 번째와 두 번째 열을 합쳐서 저장\n",
    "            input_lang.addSentence(sentence1[i]) # 입력으로 영어를 사용\n",
    "            output_lang.addSentence(sentence2[i]) # 출력으로 프랑스어를 사용\n",
    "            pairs.append(full) # pairs에는 입력과 출력이 합쳐진 것을 사용\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence): # 문장을 단어로 분리하고 인덱스를 반환\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence): # 딕셔너리에서 단어에 대한 인덱스를 가져오고 문장 끝에 토큰을 추가\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype = torch.long, device = device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(input_lang, output_lang, pair): # 입력과 출력 문장을 텐서로 변환하여 반환\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim # 인코더에서 사용할 입력층\n",
    "        self.embbed_dim = embbed_dim # 인코더에서 사용할 임베딩 계층\n",
    "        self.hidden_dim = hidden_dim # 인코더에서 사용할 은닉층(이전 은닉층)\n",
    "        self.num_layers = num_layers # 인코더에서 사용할 GRU의 계층 개수\n",
    "        self.embedding = nn.Embedding(input_dim, self.embbed_dim) # 임베딩 계층 초기화\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers = self.num_layers) # 임베딩 차원, 은닉층 차원, GRU의 계층 개수를 이용하여 GRU 게층을 초기화\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src).view(1, 1, -1) # 임베딩 처리\n",
    "        outputs, hidden = self.gru(embedded) # 임베딩 결과를 GRU 모델에 적용\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embbed_dim = embbed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, self.embbed_dim) # 임베딩 계층 초기화\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers = self.num_layers) # GRU 계층 초기화\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim) # 선형 계층 초기화\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1, -1) # 입력을 (1, 배치 크기)로 변경\n",
    "        embedded = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        prediction = self.softmax(self.out(output[0]))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, MAX_LENGTH = MAX_LENGTH):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder # 인코더 초기화\n",
    "        self.decoder = decoder # 디코더 초기화\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_lang, output_lang, teacher_forcing_ratio = 0.5):\n",
    "        input_length = input_lang.size(0) # 입력 문자 길이(문장의 단어 수)\n",
    "        batch_size = output_lang.shape[1]\n",
    "        target_length = output_lang.shape[0]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device) # 예측된 출력을 저장하기 위한 변수 초기화\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_lang[i]) # 문장의 모든 단어를 인코딩\n",
    "        decoder_hidden = encoder_hidden.to(device) # 인코더의 은닉층을 디코더의 은닉층으로 사용\n",
    "        decoder_input = torch.tensor([SOS_token], device = device) # 첫 번째 예측 단어 앞에 토큰(SOS) 추가\n",
    "\n",
    "        for t in range(target_length): # 현재 단어에서 출력 단어를 예측\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            input = (output_lang[t] if teacher_force else topi) # teacher_force를 활성화하면 목표 단어를 다음 입력으로 사용\n",
    "            if(teacher_force == False and input.item() == EOS_token): # teacher_force를 활성화하지 않으면 자체 예측 값을 다음 입력으로 사용\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], target_tensor[ot]) # 모델의 예측 결과와 정답(예상 결과)을 이용하여 오차를 계산\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, input_lang, output_lang, pairs, num_iteration = 20000):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.01) # 옵티마이저로 SGD를 사용\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss_iterations = 0\n",
    "\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs)) for i in range(num_iteration)]    \n",
    "\n",
    "    for iter in range(1, num_iteration + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion) # Model 객체를 이용하여 오차 계산\n",
    "        total_loss_iterations += loss\n",
    "\n",
    "        if iter % 5000 == 0: # 5000번째마다 오차 값에 대해 출력\n",
    "            average_loss = total_loss_iterations / 5000\n",
    "            total_loss_iterations = 0\n",
    "            print('%d %.4f'%(iter, average_loss))\n",
    "\n",
    "    torch.save(model.state_dict(), 'D:/kim/kim/DP/data/mytraining.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, input_lang, output_lang, sentences, max_length = MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0]) # 입력 문자열을 텐서로 변환\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1]) # 출력 문자열을 텐서로 변환\n",
    "        decoded_words = []\n",
    "        output = model(input_tensor, output_tensor)\n",
    "\n",
    "        for ot in range(output.size(0)):\n",
    "            topv, topi = output[ot].topk(1) # 각 출력에서 가장 높은 값을 찾아 인덱스를 반환\n",
    "\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>') # EOS 토큰을 만나면 평가를 멈춤\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()]) # 예측 결과를 출력 문자열에 추가\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(model, input_lang, output_lang, pairs, n = 10): # 훈련 데이터셋으로부터 임이의 문장을 가져와서 모델 평가\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs) # 임의로 문장을 가져옴\n",
    "        print('input {}'.format(pair[0]))\n",
    "        print('output {}'.format(pair[1]))\n",
    "        output_words = evaluate(model, input_lang, output_lang, pair) # 모델 평가 결과는 output_words에 저장\n",
    "        output_sentences = ' '.join(output_words)\n",
    "        print('predicted {}'.format(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence ['i study korean.', \"j'etudie le coreen.\"]\n",
      "Input : 23191 Output : 39387\n",
      "Encoder(\n",
      "  (embedding): Embedding(23191, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(39387, 256)\n",
      "  (gru): GRU(256, 512)\n",
      "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n",
      "5000 5.0183\n",
      "10000 4.8081\n",
      "15000 4.6846\n",
      "20000 4.6998\n",
      "25000 4.6793\n",
      "30000 4.6560\n",
      "35000 4.6163\n",
      "40000 4.6692\n",
      "45000 4.6113\n",
      "50000 4.6405\n",
      "55000 4.6162\n",
      "60000 4.6174\n",
      "65000 4.5488\n",
      "70000 4.5811\n",
      "75000 4.5339\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'eng' # 입력으로 사용할 영어\n",
    "lang2 = 'fra' # 출력으로 사용할 프랑스어\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
    "\n",
    "randomize = random.choice(pairs)\n",
    "print('random sentence {}'.format(randomize))\n",
    "\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "print('Input : {} Output : {}'.format(input_size, output_size)) # 입력과 출력에 대한 단어 수 출력\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 75000 # 7만 5000번 반복하여 모델 훈련\n",
    "# 인코더에 훈련 데이터셋을 입력하고 모든 출력과 은닉 상태를 저장\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "# 디코더의 첫 번째 입력으로 <SOS> 토큰이 제공되고, 인코더의 마지막 은닉 상태가 디코더의 첫 번째 은닉 상태로 제공됨\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device) # 인코더-디코더 모델(seq2seq)의 객체 생성\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "\n",
    "model = trainModel(model, input_lang, output_lang, pairs, num_iteration) # 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hamlet is a play by shakespeare.\n",
      "output hamlet est une piece de shakespeare.\n",
      "predicted je ne que <EOS>\n",
      "input he is far from perfect.\n",
      "output il est loin d'etre parfait.\n",
      "predicted je ne que <EOS>\n",
      "input you've been infected.\n",
      "output vous avez ete infecte.\n",
      "predicted je ne que <EOS>\n",
      "input what are you crunching on?\n",
      "output qu'est-ce que tu rumines ?\n",
      "predicted je ne que <EOS>\n",
      "input as far as the eye could see, there was nothing but sand.\n",
      "output aussi loin que l'il pouvait porter, il n'y avait rien que du sable.\n",
      "predicted je ne que <EOS>\n",
      "input there are many earthquakes in japan.\n",
      "output il y a de nombreux tremblements de terre au japon.\n",
      "predicted je ne que <EOS>\n",
      "input i need to go.\n",
      "output je dois y aller.\n",
      "predicted je ne que <EOS>\n",
      "input i promise you i'll help you.\n",
      "output je vous promets de vous aider.\n",
      "predicted je ne que <EOS>\n",
      "input i put your suitcases in your room.\n",
      "output je mets vos valises dans votre chambre.\n",
      "predicted je ne que <EOS>\n",
      "input would you care for some more cake?\n",
      "output voudriez-vous davantage de gateau ?\n",
      "predicted je ne que <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(model, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
